
---
title: "Read in Initial data"
format: html
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

```


***WARNING:*** You MUST run this script from top to bottom.  Running only part of it will result in errors.  data frames are named the same thing at the begining of the script as the end.  This improves performance in large data sets, but means that great care should be taken when the script is not run from top to bottom.

***FIRST*** Be sure to set up your farm name and state name on lines 51 and 52 if you are not going to customize the functions to set these.

***NEXT*** Pull events from dairy comp using this code:

Option 1 Pull 5 years in one file: EVENTS\2S2000C #1 #2 #4 #5 #6 #11 #12 #13 #15 #28 #29 #30 #31 #32 #38 #40 #43

Option 2 pull smaller time frames using "days back" starting with "S""days back" and ending with "L""days back":  EVENTS\2S99L0C #1 #2 #4 #5 #6 #11 #12 #13 #15 #28 #29 #30 #31 #32 #38 #40 #43

This code pulls the following items:

"ID" "PEN" "REG" "EID" "CBRD" "BDAT" "EDAT" "LACT" "RC" "HDAT" "FDAT" "CDAT" "DDAT" "PODAT" "ABDAT" "VDAT"   "ARDAT" 

"Event" "DIM" "Date" "Remark" "Protocols" "R" "T" "B"  "Technician"

If there are additional items you would like to add, you may add them to the pull code, as long as you do not delete any existing items.

***THEN*** Place your csv files generated by the dairy comp command(s) in this folder: "data/event_files"

The code in chunk 3 will read in all files in this folder so do not leave old files here that you do not want to process.

***Next To Last*** Turn on/off (comment/un-comment) lines 128 and 131 to use custom functions for event types and source farm/state

***FINALLY*** save this markdown.  You can run it manaually or run both step1 and step2 using the step0_master_processing.R script


```{r}
library(tidyverse)
library(dtplyr)
library(gt)
library(arrow)
library(lintr)
library(styler)

#custom functions, turn off or on  on line 124 and 126

source('functions/fxn_event_type.R') #custom function to identify source state based on farm
source('functions/fxn_location_event.R') #custom function to specify event location
source('functions/fxn_sourcefarms.R') #custom function to specify event location

#set defaults ------------
set_farm_name<-'Default Farm Name'
set_farm_state<-'Default Farm State'
set_location_event<-'Default Event Location'



```


```{r read in files}

list_files<-list.files('data/event_files') #folder name where event files are located

events<-NULL

for (i in seq_along(list_files)){
  df<-read_csv(paste0('data/event_files/', 
                      list_files[i]), 
               #reads in all data as character string
               col_types = cols(.default = 'c'))|> 
    mutate(remark = str_replace_all(Remark, "[^[:alnum:]]", "_"), #gets rid of weird characters that mess up encoding or parsing
           source_file_path = paste0('data/event_files/', list_files[i])
           ) 
    
  events<-bind_rows(events, df)
}


```


```{r initial cleanup}
events2<-events|>
  select(-starts_with('...'))|> #get rid of extra columns created by odd parsing in the original csv file
  #create unique cow id--------------------------------------- 
  mutate(id_animal = paste0(ID, '_', BDAT), 
         id_animal_lact = paste0(ID, '_', BDAT, '_', LACT), 
         breed = CBRD)|>
  #format dates--------------------------------------- 
  mutate(date_event = lubridate::mdy(Date), 
         
         date_birth = lubridate::mdy(BDAT), 
         
         date_fresh = lubridate::mdy(FDAT), 
         date_dry = lubridate::mdy(DDAT),

         date_enrolled = lubridate::mdy(EDAT), 
         date_archived = lubridate::mdy(ARDAT),
        
         date_heat = lubridate::mdy(HDAT), #unnecessary to pull
         date_concieved = lubridate::mdy(CDAT), #unnecessary to pull
         date_aborted = lubridate::mdy(ABDAT), #unnecessary to pull
         date_repro_dx = lubridate::mdy(PODAT) #unnecessary to pull
         
         )|>
  #parse numbers -------------------
  mutate(dim_event = parse_number(DIM), 
         lact_number = parse_number(LACT))|>
  arrange(id_animal, date_event)|>
  distinct()|>
  #replace missing values in remark and protocols to allow grouping later----------------
  mutate(protocols = str_replace_na(Protocols, 'BLANK_UNKNOWN'), 
         remark = str_replace_na(Remark, 'BLANK_UNKNOWN'),
         event = str_replace_na(Event, 'BLANK_UNKNOWN'))|>
  #add standard event types-----------------
  fxn_event_type_default()|>
  #add default source farm info-----------------
  fxn_add_source_farm_default()|>
  #add event location --------------
  fxn_add_location_event_default()|>
  #qc enrollment---------------------
  mutate(qc_diff_bdat_edat = as.numeric(date_enrolled-date_birth))


```


```{r generate event_type template}
#create event type template---------------------
  template_event_type <- events2|>
    group_by(Event, Protocols, event_type)|>
    summarize(count = sum(n()))|>
    ungroup()
  
write_csv(template_event_type, 'data/template_files/template_event_type.csv') #this is intentionally a csv because it is a template to be edited
  
```

```{r farm custom variables}
#define event types------------------------------------
  events2 <-events2|>
  
  #standardize event type--------------------
  #fxn_event_type_custom()|> # turn this off or on, you must modify this function in the function file
  
  #add source farm ------------------
  #fxn_add_source_farm_custom() |> # turn this off or on, you must modify this function in the function file
  
  #fix na values-------------
  mutate(
    event_type = case_when(
      is.na(event_type)~'Unknown',
      TRUE~event_type), 
    source_farm = case_when(
      is.na(source_farm)~'Unknown', 
      TRUE~source_farm), 
    source_state = case_when(
      is.na(source_state)~'Unknown', 
      TRUE~source_state),
    breed = case_when(
      is.na(breed)~'Unknown', 
      TRUE~breed),
    technician = case_when(
      is.na(Technician)~'Unknown', 
      TRUE~Technician),
    eid = case_when(
      is.na(EID)~'Unknown', 
      TRUE~EID)
  )|>
  # create lactation groups ---------------------intentionally not a function so it is obvious...but could make it a function
  mutate(
    lact_group_basic = case_when(
      (lact_number == 0)~'Heifer', 
      (lact_number >0)~'LACT > 0',
      TRUE~'Unknown'), 
    lact_group_repro = case_when(
      (lact_number == 0)~'Heifer', 
      (lact_number ==1)~'LACT 1',
      (lact_number >1)~'LACT 2+',
      TRUE~'Unknown'),
    lact_group = case_when(
      (lact_number == 0)~'Heifer', 
      (lact_number ==1)~'LACT 1',
      (lact_number ==2)~'LACT 2',
      (lact_number >2)~'LACT 3+',
      TRUE~'Unknown')
    )


```


```{r write out files}

# main file ------------
write_parquet(events2, 'data/intermediate_files/events_all_columns.parquet') # this file is for if you wanted to chase a problem between original and formatted file without re-running step1

# formatted file -----------------------
write_parquet(events2%>%
                select(source_file_path, source_farm, source_state, 
                       id_animal, date_birth, breed, eid, date_enrolled, qc_diff_bdat_edat,
                       id_animal_lact, date_archived, 
                       lact_number, lact_group_basic, lact_group, lact_group_repro,
                       event_type, event, remark, protocols, technician, date_event, dim_event, location_event,
                       R, `T`, B, date_heat, date_concieved, date_aborted, date_repro_dx
                       ), 'data/intermediate_files/events_formatted.parquet')


# data quality files------------
qc_animal_enrollment<-events2|>
  mutate(qc_valid_enrollment = case_when(
  (qc_diff_bdat_edat==0)~'Valid', 
  TRUE~'Not Valid'))|>
  group_by(qc_valid_enrollment)|>
  summarize(ct_animals = n_distinct(id_animal))|>
  ungroup()

write_parquet(qc_animal_enrollment, 'data/qc_files/qc_animal_enrollment.parquet')

qc_event_type<-events2|>
  filter(event_type %in% 'Unknown')|>
  group_by(Event, Protocols, event_type)|>
  summarize(count = sum(n()))|>
  ungroup()

write_parquet(qc_event_type, 'data/qc_files/qc_event_type.parquet')

qc_source_farm<-events2|>
  filter(source_farm %in% 'Unknown')|>
  group_by(Event, Protocols, source_farm)|>
  summarize(count = sum(n()))|>
  ungroup()
write_parquet(qc_source_farm, 'data/qc_files/qc_source_farm.parquet')

total_animals<-events2|>
  mutate(year = year(date_event))|>
  group_by(year, lact_group)|>
  summarize(count_animals = n_distinct(id_animal), 
            count_lactations = n_distinct(id_animal_lact)
            )|>
  ungroup()

# set figure widths for chunk below ---------------
fig_width = dim(qc_event_type)[1]*.5
fig_height = dim(qc_event_type)[2]*3

              

```

## Initial Processing Report

#### Start date: `r min(events2$date_event)`

#### End date: `r max(events2$date_event)`

### Animal Counts

```{r}
total_animals|>
  select(-count_lactations)|>
  pivot_wider(names_from = 'lact_group', 
              values_from = 'count_animals')|>
  gt()

ggplot(total_animals)+
  geom_bar(aes(x = factor(year), y = count_animals), stat = 'identity')+
  facet_grid(.~lact_group)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```



### QC Event Types
Events not classified 

```{r, fig.width = fig_width, fig.height = fig_height}
if (dim(qc_event_type)[1]<1){
  print('All Event Types Mapped')
}else{
  ggplot(qc_event_type)+
    geom_bar(aes(x = Protocols, y = count), stat = 'identity', fill = 'red')+
    facet_wrap(Event~., scales = 'free_x', ncol = 6)+
    theme(axis.text.x = element_text(angle= 45, hjust = 1))
}

summarize_event_type<-events2|>
         group_by(event_type, lact_group)|>
         summarize(count_id_animal = n_distinct(id_animal))|>
         ungroup()

```




## QC Animals

```{r}

qc_animals<-events2%>%
  mutate(diff_bdat_edat = date_enrolled-date_birth)%>%
  #filter((diff_bdat_edat<0)|(diff_bdat_edat>2))%>%
  select(id_animal, date_birth, date_enrolled, diff_bdat_edat, everything())

```



### Main data

```{r, fig.show="hold", out.width="50%"}
main_data<-events2|>
  group_by(Event, event_type)|>
  summarize(count_id_animal = n_distinct(id_animal))|>
  ungroup()

list_event_types<-sort(unique(main_data$event_type))

#i=1
for (i in seq_along(list_event_types)){
p<-ggplot(main_data|>filter(event_type %in% list_event_types[[i]]))+
  geom_bar(aes(x = Event, y = count_id_animal), stat = 'identity')+
  facet_wrap(event_type~., scales = 'free')+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = paste0(list_event_types[[i]]))

print(p)
}
  
```

### Missing Values

```{r}
sk_events2<-skimr::skim(events2)

ggplot(sk_events2)+
  geom_bar(aes(x = skim_variable, y = 1-complete_rate), stat = 'identity')+
  facet_wrap(skim_type~., scales = 'free', nrow = 3)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  ylab('Percent Missing Values')

```









